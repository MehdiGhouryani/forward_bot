# parser.py
import re
import logging
from telethon.tl.types import MessageEntityTextUrl
import traceback


def transform_message(message_text, message_entities):
    """Ù¾ÛŒØ§Ù… Ø®Ø§Ù… ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù„Ú¯ÙˆÛŒ Ø¬Ø¯ÛŒØ¯ ğŸ¥ ØªØ¬Ø²ÛŒÙ‡ Ùˆ Ø¨Ù‡ ÙØ±Ù…Øª ÙØ§Ø±Ø³ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    logging.info("Starting message transformation")
    logging.debug(f"Raw input message: {message_text[:100]}...")

    pattern = r"""
        ğŸ¥\s*(0x[a-fA-F0-9]{40})\s*\n
        ğŸš¨[ğŸš¨\s]*\n
        \n
        â”Œ([^\(]+)\s*\(([^\)]+)\)\s*\n
        â”œUSD:\s*\$([\d\.]+)\s*\n
        â”œMC:\s*\$([\d\.KMB]+)\s*\n
        â”œVol:\s*\$([\d\.KMB]+)\s*\n
        â”œSeen:\s*([^\n]+)\s*\n
        â”œDex:\s*([^\n]+)\s*\n
        â”œDex\ Paid:\s*([ğŸ”´ğŸŸ¢])\s*\n
        â”œCA\ Verified:\s*([ğŸ”´ğŸŸ¢])\s*\n
        â”œTax:\s*([^\n]+)\s*\n
        â”œHoneypot:\s*([^\n]+)\s*\n
        â”œHolder:\s*Top\ 10:\s*([ğŸŸ¡ğŸŸ¢])\s*(\d+%)\s*\n
        â””TH:\s*([^\n]+)\s*\n
        \n
        ğŸ”[^\n]*\n
        [^\n]*\n
        \n
        ğŸ“ˆ\s*Chart:\s*\[\]\((https://mevx\.io/[^\s?]+(?:\?[^\)\s]*)?)\)[ \t]*
        (?:\n\n(ğŸ”¥[^\n]+))?
    """
    match = re.match(pattern, message_text, re.VERBOSE | re.DOTALL)
    if not match:
        logging.warning(f"Message does not match new ğŸ¥ pattern: {message_text[:50]}...")
        return None, None, None, None, None

    try:
        groups = match.groups()
        token_address = groups[0]
        token_name = groups[1].strip()
        token_symbol = groups[2].strip()
        usd = groups[3]
        mc = groups[4]
        vol = groups[5]
        seen = groups[6]
        dex = groups[7]
        dex_paid = groups[8]
        ca_verified = groups[9]
        tax = groups[10]
        honeypot = groups[11]
        holder_color = groups[12]
        holder_percentage = groups[13]
        th_values_str = groups[14].strip()
        chart_url = groups[15] # Ù„ÛŒÙ†Ú© mevx.io
        x_info = groups[16] # Ø¨Ù„Ø§Ú© Ø§Ø®ØªÛŒØ§Ø±ÛŒ ğŸ”¥

        th_numeric_values = []
        if th_values_str:
            th_items = th_values_str.split("|")
            for item in th_items[:10]: # Ù¾Ø±Ø¯Ø§Ø²Ø´ Û±Û° Ù‡ÙˆÙ„Ø¯Ø±
                item_stripped = item.strip()
                th_numeric_values.append(item_stripped or "0")
        logging.info(f"Extracted TH numeric values: {th_numeric_values}")

        while len(th_numeric_values) < 10:
            th_numeric_values.append("0")

        th_text = "|".join(th_numeric_values)
        logging.info(f"Formatted TH text for output: {th_text}")

        new_message = (
            f"âš¡ï¸ <code>{token_address}</code>\n"
            f"â€¢ {token_name} ({token_symbol})\n"
            f"â€¢ Ù‚ÛŒÙ…Øª:      ${usd}\n"
            f"â€¢ Ù…Ø§Ø±Ú©Øªâ€ŒÚ©Ù¾:     ${mc}\n"
            f"â€¢ Ø­Ø¬Ù…:      ${vol}\n"
            f"â€¢ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡:      {seen}\n"
            f"â€¢ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ:      {dex}\n"
            f"â€¢ Ø¯Ú©Ø³ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ØŸ: {dex_paid}\n"
            f"â€¢ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯Ù‡ØŸ: {ca_verified}\n"
            f"â€¢ Ù…Ø§Ù„ÛŒØ§Øª: {tax}\n"
            f"â€¢ Ù‡Ø§Ù†ÛŒâ€ŒÙ¾Ø§Øª: {honeypot}\n"
            f"â€¢ Ù‡ÙˆÙ„Ø¯Ø±Ù‡Ø§:     Top 10: {holder_color} {holder_percentage}\n"
            f"â€¢ ØªØ§Ù¾ Ù‡ÙˆÙ„Ø¯Ø±:      {th_text}"
        )

        if x_info:
            new_message += f"\n\n{x_info.strip()}"

        if len(new_message) > 4096:
            logging.error(f"Transformed message too long: {len(new_message)} characters. Truncating.")
            new_message = new_message[:4090] + "..."

        # Ø¯Ø± ÙØ§Ø² Û±ØŒ Ù‡ÛŒÚ† Entity Ø¨Ø±Ø§ÛŒ Ù…ØªÙ† Ù¾ÛŒØ§Ù… Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ….
        new_entities = []
        
        # th_pairs Ø¯ÛŒÚ¯Ø± Ø­Ø§ÙˆÛŒ Ù„ÛŒÙ†Ú© Ù†ÛŒØ³ØªØŒ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ø¨Ø§ ØµÙ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        # Ø¯Ø± ÙØ§Ø²Ù‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§ÛŒÙ† Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯.
        th_pairs = [(val, None) for val in th_numeric_values]

        logging.debug(f"Final entities for output: {new_entities}")
        # Ø¢Ø¯Ø±Ø³ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ (token_address) Ø¨Ø±Ø§ÛŒ ÙØ§Ø² Û² Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return new_message, new_entities, chart_url, th_pairs, token_address

    except Exception as e:
        logging.error(f"Unhandled error in transform_message: {e}\n{traceback.format_exc()}")
        return None, None, None, None, None

def entities_to_html(entities, text):
    """Ù„ÛŒØ³Øª Entity ØªÙ„ØªÙˆÙ† Ø±Ø§ Ø¨Ù‡ Ù…ØªÙ† HTML Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø§ python-telegram-bot ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not entities:
        # Ø§Ú¯Ø± Entity ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù…ØªÙ† Ø±Ø§ HTML Ø¯Ø± Ù†Ø¸Ø± Ù†Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
        # Ø§Ù…Ø§ Ú†ÙˆÙ† Ù…Ø§ Ø§Ø² <code> Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…ØŒ Ø¨Ø§ÛŒØ¯ HTML Ø¨Ø§Ø´Ø¯
        return text, "HTML"

    html_text = text
    offset_adjustment = 0

    for entity in sorted(entities, key=lambda e: e.offset):
        start = entity.offset + offset_adjustment
        end = start + entity.length
        entity_text = html_text[start:end]

        if isinstance(entity, MessageEntityTextUrl):
            html_entity = f'<a href="{entity.url}">{entity_text}</a>'
            html_text = html_text[:start] + html_entity + html_text[end:]
            offset_adjustment += len(html_entity) - len(entity_text)

    return html_text, "HTML"