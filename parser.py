import re
import logging
from telethon.tl.types import MessageEntityTextUrl
import traceback


logger = logging.getLogger(__name__)

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ù‡Ø± Ø®Ø· (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ---

def _parse_token_name(line):
    """
    'â”ŒJUDICA (JUDICA) (https://...)' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø§Ú©Ù†ÙˆÙ† URL Ø±Ø§ Ù†ÛŒØ² Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    match = re.search(r'â”Œ([^\(]+)\s*\(([^\)]+)\)\s*\((https://[^\)]+)\)', line)
    if match:
        # Ù†Ø§Ù…ØŒ Ù†Ù…Ø§Ø¯ØŒ Ùˆ URL
        return match.group(1).strip(), match.group(2).strip(), match.group(3)
    
    # ÙØ§Ù„â€ŒØ¨Ú© Ø¨Ø±Ø§ÛŒ Ø­Ø§Ù„ØªÛŒ Ú©Ù‡ Ù„ÛŒÙ†Ú© ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
    match_no_link = re.search(r'â”Œ([^\(]+)\s*\(([^\)]+)\)', line)
    if match_no_link:
        return match_no_link.group(1).strip(), match_no_link.group(2).strip(), None
        
    return 'N/A', 'N/A', None

def _parse_usd(line):
    """ 'â”œUSD: $0.0002268' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'\$([\d\.]+)', line)
    return match.group(1) if match else 'N/A'

def _parse_mc_vol(line):
    """ 'â”œMC: $226.8K' ÛŒØ§ 'â”œVol: $88.2K' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'\$([\d\.KMB]+)', line)
    return match.group(1) if match else 'N/A'

def _parse_simple_text(line, prefix):
    """ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾ÛŒØ´ÙˆÙ†Ø¯ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ """
    return line.replace(prefix, '').strip()

def _parse_emoji_status(line):
    """ Ø§ÛŒÙ…ÙˆØ¬ÛŒ ğŸ”´ ÛŒØ§ ğŸŸ¢ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ """
    if 'ğŸ”´' in line: return 'ğŸ”´'
    if 'ğŸŸ¢' in line: return 'ğŸŸ¢'
    return 'N/A'

def _parse_holder(line):
    """ 'â”œHolder: Top 10: ğŸŸ¡ 55%' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'Top 10:\s*([ğŸŸ¡ğŸŸ¢])\s*(\d+%)', line)
    if match:
        return match.group(1), match.group(2)
    return 'N/A', 'N/A'

def _parse_th(line):
    """
    'â””TH: 13.3% (https://...)| 6.3% ...' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ù„ÛŒØ³ØªÛŒ Ø§Ø² (Ø¯Ø±ØµØ¯ØŒ URL) Ù‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    # Ø§Ù„Ú¯ÙˆÛŒ Regex Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬ÙØªâ€ŒÙ‡Ø§ÛŒ (Ø¯Ø±ØµØ¯) Ùˆ (Ù„ÛŒÙ†Ú©)
    pairs = re.findall(r'([\d\.]+\%?)\s*\((https://[^\)]+)\)', line)
    
    # Û±Û° ØªØ§ÛŒ Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
    return pairs[:10]

def _parse_chart(line):
    """ 'ğŸ“ˆ Chart: https://mevx.io/...' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'(https://mevx\.io/[^\s]+)', line)
    return match.group(1) if match else None

# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ØªØ¬Ø²ÛŒÙ‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ---

def transform_message(message_text, message_entities):
    """
    Ù¾ÛŒØ§Ù… Ø®Ø§Ù… ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ø· Ø¨Ù‡ Ø®Ø· ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    (Ù†Ø³Ø®Ù‡ Ù…Ù‚Ø§ÙˆÙ… Ø¨Ø§ Ù‡Ø§ÛŒÙ¾Ø±Ù„ÛŒÙ†Ú©)
    """
    logger.debug(f"Starting line-by-line transformation (with Hyperlinks)...")
    
    data = {}
    th_values = [] # Ø§Ú©Ù†ÙˆÙ† Ù„ÛŒØ³ØªÛŒ Ø§Ø² ØªØ§Ù¾Ù„â€ŒÙ‡Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯
    x_info = None

    try:
        lines = message_text.split('\n')

        if not lines or not lines[0].startswith("ğŸ¥"):
            logger.warning("Message does not start with ğŸ¥ trigger. Skipping.")
            return None, None, None, None, None
        
        data['token_address'] = lines[0].replace('ğŸ¥', '').strip()
        if not re.match(r'^(0x[a-fA-F0-9]{40})$', data['token_address']):
             logger.warning(f"Failed to parse Token Address: {lines[0]}")
             data['token_address'] = 'Error'

        for line in lines[1:]:
            line = line.strip()
            if not line:
                continue

            try:
                if line.startswith('â”Œ'):
                    # [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø§Ú©Ù†ÙˆÙ† Û³ Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                    data['token_name'], data['token_symbol'], data['token_url'] = _parse_token_name(line)
                elif line.startswith('â”œUSD:'):
                    data['usd'] = _parse_usd(line)
                elif line.startswith('â”œMC:'):
                    data['mc'] = _parse_mc_vol(line)
                elif line.startswith('â”œVol:'):
                    data['vol'] = _parse_mc_vol(line)
                elif line.startswith('â”œSeen:'):
                    data['seen'] = _parse_simple_text(line, 'â”œSeen:')
                elif line.startswith('â”œDex:'):
                    data['dex'] = _parse_simple_text(line, 'â”œDex:')
                elif line.startswith('â”œDex Paid:'):
                    data['dex_paid'] = _parse_emoji_status(line)
                elif line.startswith('â”œCA Verified:'):
                    data['ca_verified'] = _parse_emoji_status(line)
                
                # [Ø­Ø°Ù Ø´Ø¯Ù‡] Ø®Ø· Tax Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
                # elif line.startswith('â”œTax:'):
                #     data['tax'] = _parse_simple_text(line, 'â”œTax:')
                    
                elif line.startswith('â”œHoneypot:'):
                    data['honeypot'] = _parse_simple_text(line, 'â”œHoneypot:')
                elif line.startswith('â”œHolder:'):
                    data['holder_color'], data['holder_percentage'] = _parse_holder(line)
                elif line.startswith('â””TH:'):
                    # [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø§Ú©Ù†ÙˆÙ† Ù„ÛŒØ³ØªÛŒ Ø§Ø² (Ø¯Ø±ØµØ¯ØŒ Ù„ÛŒÙ†Ú©) Ù‡Ø§ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                    th_values = _parse_th(line)
                elif line.startswith('ğŸ“ˆ Chart:'):
                    data['chart_url'] = _parse_chart(line)
                elif line.startswith('ğŸ”¥'):
                    x_info = line
            
            except Exception as e:
                logger.warning(f"Failed to parse line: '{line}'. Error: {e}")

        # --- Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù… Ø®Ø±ÙˆØ¬ÛŒ (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ---
        
        token_address = data.get('token_address', 'N/A')
        token_name = data.get('token_name', 'N/A')
        token_symbol = data.get('token_symbol', '?')
        token_url = data.get('token_url', '#') # Ù„ÛŒÙ†Ú© bscscan ØªÙˆÚ©Ù†
        
        # [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø³Ø§Ø®Øª Ù‡Ø§ÛŒÙ¾Ø±Ù„ÛŒÙ†Ú© Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… ØªÙˆÚ©Ù†
        if token_url != '#':
            token_line = f"<a href='{token_url}'>{token_name}</a> ({token_symbol})"
        else:
            token_line = f"{token_name} ({token_symbol})" # ÙØ§Ù„â€ŒØ¨Ú© Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ù†Ø¨ÙˆØ¯

        # [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø³Ø§Ø®Øª Ù‡Ø§ÛŒÙ¾Ø±Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ§Ù¾ Ù‡ÙˆÙ„Ø¯Ø±Ù‡Ø§
        th_links = []
        if th_values: # th_values Ø§Ú©Ù†ÙˆÙ† Ù„ÛŒØ³ØªÛŒ Ø§Ø² (Ø¯Ø±ØµØ¯ØŒ Ù„ÛŒÙ†Ú©) Ø§Ø³Øª
            for percent, url in th_values:
                th_links.append(f"<a href='{url}'>{percent}</a>")
            th_text = " | ".join(th_links)
        else:
            th_text = "N/A" # ÙØ§Ù„â€ŒØ¨Ú© Ø§Ú¯Ø± Ù‡ÙˆÙ„Ø¯Ø±ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯
        
        # Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¯ÛŒÚ¯Ø±
        usd = data.get('usd', '?')
        mc = data.get('mc', '?')
        vol = data.get('vol', '?')
        seen = data.get('seen', '?')
        dex = data.get('dex', '?')
        dex_paid = data.get('dex_paid', '?')
        ca_verified = data.get('ca_verified', '?')
        honeypot = data.get('honeypot', '?')
        holder_color = data.get('holder_color', '?')
        holder_percentage = data.get('holder_percentage', '?')
        chart_url = data.get('chart_url')

        # [Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡] Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ
        new_message = (
            f"âš¡ï¸ <code>{token_address}</code>\n"
            f"â€¢ {token_line}\n"  # <--- Ø§ÛŒÙ†Ø¬Ø§ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯
            f"â€¢ Ù‚ÛŒÙ…Øª:      ${usd}\n"
            f"â€¢ Ù…Ø§Ø±Ú©Øªâ€ŒÚ©Ù¾:     ${mc}\n"
            f"â€¢ Ø­Ø¬Ù…:      ${vol}\n"
            f"â€¢ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡:      {seen}\n"
            f"â€¢ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ:      {dex}\n"
            f"â€¢ Ø¯Ú©Ø³ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ØŸ: {dex_paid}\n"
            f"â€¢ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯Ù‡ØŸ: {ca_verified}\n"
            # f"â€¢ Ù…Ø§Ù„ÛŒØ§Øª: {tax}\n"  <--- Ø§ÛŒÙ†Ø¬Ø§ Ø­Ø°Ù Ø´Ø¯
            f"â€¢ Ù‡Ø§Ù†ÛŒâ€ŒÙ¾Ø§Øª: {honeypot}\n"
            f"â€¢ Ù‡ÙˆÙ„Ø¯Ø±Ù‡Ø§:     Top 10: {holder_color} {holder_percentage}\n"
            f"â€¢ ØªØ§Ù¾ Ù‡ÙˆÙ„Ø¯Ø±:      {th_text}"  # <--- Ø§ÛŒÙ†Ø¬Ø§ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯
        )

        if x_info:
            new_message += f"\n\n{x_info.strip()}"

        if len(new_message) > 4096:
            logger.error(f"Transformed message too long: {len(new_message)} characters. Truncating.")
            new_message = new_message[:4090] + "..."

        # --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ (Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ bot.py) ---
        new_entities = []
        # th_pairs Ø§Ú©Ù†ÙˆÙ† Ø­Ø§ÙˆÛŒ ØªØ§Ù¾Ù„â€ŒÙ‡Ø§ÛŒ (Ø¯Ø±ØµØ¯ØŒ Ù„ÛŒÙ†Ú©) Ø§Ø³Øª Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ù…Ø´Ú©Ù„ÛŒ Ù†Ø¯Ø§Ø±Ø¯
        th_pairs = th_values

        logger.info(f"Message successfully parsed (line-by-line, with hyperlinks): {token_address}")
        
        # Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ø§ Ú†ÛŒØ²ÛŒ Ú©Ù‡ bot.py Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø§Ø±Ø¯ Ù…Ø·Ø§Ø¨Ù‚Øª Ø¯Ø§Ø±Ø¯
        return new_message, new_entities, chart_url, th_pairs, token_address

    except Exception as e:
        logger.critical(f"CRITICAL error in transform_message: {e}\n{traceback.format_exc()}")
        logger.error(f"--- FAILED MESSAGE (CRITICAL) ---\n{message_text}\n--- END ---")
        return None, None, None, None, None


def entities_to_html(entities, text):
    """(Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)"""
    if not entities:
        return text, "HTML"

    html_text = text
    offset_adjustment = 0

    for entity in sorted(entities, key=lambda e: e.offset):
        start = entity.offset + offset_adjustment
        end = start + entity.length
        entity_text = html_text[start:end]

        if isinstance(entity, MessageEntityTextUrl):
            html_entity = f'<a href="{entity.url}">{entity_text}</a>'
            html_text = html_text[:start] + html_entity + html_text[end:]
            offset_adjustment += len(html_entity) - len(entity_text)

    return html_text, "HTML"