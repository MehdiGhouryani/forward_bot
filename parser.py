# parser.py
import re
import logging
from telethon.tl.types import MessageEntityTextUrl
import traceback

# Ù„Ø§Ú¯Ø± Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù…Ø®ØµÙˆØµ Ø§ÛŒÙ† Ù…Ø§Ú˜ÙˆÙ„
logger = logging.getLogger(__name__)

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ù‡Ø± Ø®Ø· ---
# Ø§ÛŒÙ† ØªÙˆØ§Ø¨Ø¹ Ú©ÙˆÚ†Ú© Ø¨Ù‡ Ù…Ø§ Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ù‡Ø± Ø®Ø· Ø±Ø§ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†ÛŒÙ…

def _parse_token_name(line):
    """ 'â”ŒJUDICA (JUDICA) (...)' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'â”Œ([^\(]+)\s*\(([^\)]+)\)', line)
    if match:
        return match.group(1).strip(), match.group(2).strip()
    return 'N/A', 'N/A'

def _parse_usd(line):
    """ 'â”œUSD: $0.0002268' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'\$([\d\.]+)', line)
    return match.group(1) if match else 'N/A'

def _parse_mc_vol(line):
    """ 'â”œMC: $226.8K' ÛŒØ§ 'â”œVol: $88.2K' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'\$([\d\.KMB]+)', line)
    return match.group(1) if match else 'N/A'

def _parse_simple_text(line, prefix):
    """ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² Ù¾ÛŒØ´ÙˆÙ†Ø¯ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (Ø¨Ø±Ø§ÛŒ Seen, Dex, Tax, Honeypot) """
    return line.replace(prefix, '').strip()

def _parse_emoji_status(line):
    """ Ø§ÛŒÙ…ÙˆØ¬ÛŒ ğŸ”´ ÛŒØ§ ğŸŸ¢ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ """
    if 'ğŸ”´' in line: return 'ğŸ”´'
    if 'ğŸŸ¢' in line: return 'ğŸŸ¢'
    return 'N/A'

def _parse_holder(line):
    """ 'â”œHolder: Top 10: ğŸŸ¡ 55%' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'Top 10:\s*([ğŸŸ¡ğŸŸ¢])\s*(\d+%)', line)
    if match:
        return match.group(1), match.group(2)
    return 'N/A', 'N/A'

def _parse_th(line):
    """ 'â””TH: 13.3% (...)| 6.3% ...' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ ÙÙ‚Ø· Ø¯Ø±ØµØ¯Ù‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ """
    # ØªÙ…Ø§Ù… Ø¯Ø±ØµØ¯Ù‡Ø§ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù† (Ø­ØªÛŒ Ø§Ú¯Ø± Ù„ÛŒÙ†Ú© Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯)
    percentages = re.findall(r'([\d\.]+\%?)', line)
    # Û±Û° ØªØ§ÛŒ Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ø±Ø¯Ø§Ø±
    top_ten = [p.strip() for p in percentages[:10] if p.strip()]
    # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² Û±Û° ØªØ§ Ø¨ÙˆØ¯ØŒ Ø¨Ø§ '0' Ù¾Ø± Ú©Ù†
    while len(top_ten) < 10:
        top_ten.append("0")
    return top_ten

def _parse_chart(line):
    """ 'ğŸ“ˆ Chart: https://mevx.io/...' Ø±Ø§ ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ """
    match = re.search(r'(https://mevx\.io/[^\s]+)', line)
    return match.group(1) if match else None

# --- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ØªØ¬Ø²ÛŒÙ‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ ---

def transform_message(message_text, message_entities):
    """
    Ù¾ÛŒØ§Ù… Ø®Ø§Ù… ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ø· Ø¨Ù‡ Ø®Ø· ØªØ¬Ø²ÛŒÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    ØªØ§ Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± ØªØºÛŒÛŒØ±Ø§Øª ÙØ±Ù…Øª Ù…Ù‚Ø§ÙˆÙ… Ø¨Ø§Ø´Ø¯.
    """
    logger.debug(f"Starting NEW line-by-line transformation...")
    
    # Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡
    data = {}
    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§
    th_values = ["0"] * 10
    x_info = None

    try:
        lines = message_text.split('\n')

        # --- Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ---
        if not lines or not lines[0].startswith("ğŸ¥"):
            logger.warning("Message does not start with ğŸ¥ trigger. Skipping.")
            return None, None, None, None, None
        
        # --- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ø· Ø§ÙˆÙ„ (Ø¢Ø¯Ø±Ø³) ---
        data['token_address'] = lines[0].replace('ğŸ¥', '').strip()
        if not re.match(r'^(0x[a-fA-F0-9]{40})$', data['token_address']):
             logger.warning(f"Failed to parse Token Address: {lines[0]}")
             data['token_address'] = 'Error' # Ø§Ú¯Ø± Ø¢Ø¯Ø±Ø³ Ø¨Ø¯ Ø¨ÙˆØ¯ØŒ Ø®Ø·Ø§ Ø¨Ø²Ù†

        # --- Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ø®Ø· Ø¨Ù‡ Ø®Ø· ---
        for line in lines[1:]: # Ø§Ø² Ø®Ø· Ø¯ÙˆÙ… Ø´Ø±ÙˆØ¹ Ú©Ù†
            line = line.strip()
            if not line:
                continue

            try:
                if line.startswith('â”Œ'):
                    data['token_name'], data['token_symbol'] = _parse_token_name(line)
                elif line.startswith('â”œUSD:'):
                    data['usd'] = _parse_usd(line)
                elif line.startswith('â”œMC:'):
                    data['mc'] = _parse_mc_vol(line)
                elif line.startswith('â”œVol:'):
                    data['vol'] = _parse_mc_vol(line)
                elif line.startswith('â”œSeen:'):
                    data['seen'] = _parse_simple_text(line, 'â”œSeen:')
                elif line.startswith('â”œDex:'):
                    data['dex'] = _parse_simple_text(line, 'â”œDex:')
                elif line.startswith('â”œDex Paid:'):
                    data['dex_paid'] = _parse_emoji_status(line)
                elif line.startswith('â”œCA Verified:'):
                    data['ca_verified'] = _parse_emoji_status(line)
                elif line.startswith('â”œTax:'):
                    data['tax'] = _parse_simple_text(line, 'â”œTax:')
                elif line.startswith('â”œHoneypot:'):
                    data['honeypot'] = _parse_simple_text(line, 'â”œHoneypot:')
                elif line.startswith('â”œHolder:'):
                    data['holder_color'], data['holder_percentage'] = _parse_holder(line)
                elif line.startswith('â””TH:'):
                    th_values = _parse_th(line)
                elif line.startswith('ğŸ“ˆ Chart:'):
                    data['chart_url'] = _parse_chart(line)
                elif line.startswith('ğŸ”¥'):
                    x_info = line # Ø°Ø®ÛŒØ±Ù‡ Ú©Ø±Ø¯Ù† Ø®Ø· Ø§Ø·Ù„Ø§Ø¹Ø§Øª X (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)
            
            except Exception as e:
                # Ø§Ú¯Ø± ØªØ¬Ø²ÛŒÙ‡ ÛŒÚ© Ø®Ø· Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯ØŒ ÙÙ‚Ø· Ù„Ø§Ú¯ Ú©Ù† Ùˆ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡
                logger.warning(f"Failed to parse line: '{line}'. Error: {e}")

        # --- Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ù¾ÛŒØ§Ù… Ø®Ø±ÙˆØ¬ÛŒ ---
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú©Ù„ÛŒØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
        token_address = data.get('token_address', 'N/A')
        token_name = data.get('token_name', 'N/A')
        token_symbol = data.get('token_symbol', '?')
        usd = data.get('usd', '?')
        mc = data.get('mc', '?')
        vol = data.get('vol', '?')
        seen = data.get('seen', '?')
        dex = data.get('dex', '?')
        dex_paid = data.get('dex_paid', '?')
        ca_verified = data.get('ca_verified', '?')
        tax = data.get('tax', '?')
        honeypot = data.get('honeypot', '?')
        holder_color = data.get('holder_color', '?')
        holder_percentage = data.get('holder_percentage', '?')
        th_text = "|".join(th_values)
        chart_url = data.get('chart_url') # Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ Ø¨Ø§ÛŒØ¯ None Ø¨Ø§Ø´Ø¯

        new_message = (
            f"âš¡ï¸ <code>{token_address}</code>\n"
            f"â€¢ {token_name} ({token_symbol})\n"
            f"â€¢ Ù‚ÛŒÙ…Øª:      ${usd}\n"
            f"â€¢ Ù…Ø§Ø±Ú©Øªâ€ŒÚ©Ù¾:     ${mc}\n"
            f"â€¢ Ø­Ø¬Ù…:      ${vol}\n"
            f"â€¢ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡:      {seen}\n"
            f"â€¢ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ:      {dex}\n"
            f"â€¢ Ø¯Ú©Ø³ Ù¾Ø±Ø¯Ø§Ø®Øª Ø´Ø¯Ù‡ØŸ: {dex_paid}\n"
            f"â€¢ Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ ØªØ§ÛŒÛŒØ¯ Ø´Ø¯Ù‡ØŸ: {ca_verified}\n"
            f"â€¢ Ù…Ø§Ù„ÛŒØ§Øª: {tax}\n"
            f"â€¢ Ù‡Ø§Ù†ÛŒâ€ŒÙ¾Ø§Øª: {honeypot}\n"
            f"â€¢ Ù‡ÙˆÙ„Ø¯Ø±Ù‡Ø§:     Top 10: {holder_color} {holder_percentage}\n"
            f"â€¢ ØªØ§Ù¾ Ù‡ÙˆÙ„Ø¯Ø±:      {th_text}"
        )

        if x_info:
            new_message += f"\n\n{x_info.strip()}"

        if len(new_message) > 4096:
            logger.error(f"Transformed message too long: {len(new_message)} characters. Truncating.")
            new_message = new_message[:4090] + "..."

        # --- Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®Ø±ÙˆØ¬ÛŒ (Ø³Ø§Ø²Ú¯Ø§Ø± Ø¨Ø§ bot.py) ---
        new_entities = []
        th_pairs = [(val, None) for val in th_values]

        logger.info(f"Message successfully parsed (line-by-line): {token_address}")
        
        return new_message, new_entities, chart_url, th_pairs, token_address

    except Exception as e:
        logger.critical(f"CRITICAL error in transform_message: {e}\n{traceback.format_exc()}")
        logger.error(f"--- FAILED MESSAGE (CRITICAL) ---\n{message_text}\n--- END ---")
        return None, None, None, None, None


def entities_to_html(entities, text):
    """(Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) Ù„ÛŒØ³Øª Entity ØªÙ„ØªÙˆÙ† Ø±Ø§ Ø¨Ù‡ Ù…ØªÙ† HTML Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø§ python-telegram-bot ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if not entities:
        return text, "HTML"

    html_text = text
    offset_adjustment = 0

    for entity in sorted(entities, key=lambda e: e.offset):
        start = entity.offset + offset_adjustment
        end = start + entity.length
        entity_text = html_text[start:end]

        if isinstance(entity, MessageEntityTextUrl):
            html_entity = f'<a href="{entity.url}">{entity_text}</a>'
            html_text = html_text[:start] + html_entity + html_text[end:]
            offset_adjustment += len(html_entity) - len(entity_text)

    return html_text, "HTML"